{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Veri YÃ¼kleme"
      ],
      "metadata": {
        "id": "Ebu3OyMHdpXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install torchdata"
      ],
      "metadata": {
        "id": "WpvgaY_9VKL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n"
      ],
      "metadata": {
        "id": "1WffB0H1cHod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "f = open(\"parallelcorpus.txt\", \"a\")\n",
        "\n",
        "for i in train_iter:\n",
        "  for x in [x.rstrip(\"\\n\") for x in i]:\n",
        "    f.write(x)\n",
        "    f.write(' ')\n",
        "\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "GQVFexHPCQt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "tokenizer.train(['parallelcorpus.txt'], trainer)\n",
        "\n",
        "tokenizer.enable_padding(pad_id=1, length=MAX_LEN)\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[BOS] $A [EOS]\",\n",
        "    special_tokens=[\n",
        "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
        "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "\n",
        "\n",
        "\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ],
      "metadata": {
        "id": "pRcQKR0scNow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, BATCH_SIZE, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "-OWJTwb2vod0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "V5dx7IIwdyVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, pad_mask):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x)"
      ],
      "metadata": {
        "id": "7GYWcPNjd1Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_ff = d_ff\n",
        "        self.d_k = self.d_v = int(d_model / d_h)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.concatLinear = nn.Linear(d_model, d_model, bias=False) # Linear Layer for the concatenated head\n",
        "        self.normalize = nn.LayerNorm(d_model) # Normalizing Layer\n",
        "\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k, bias=False) for _ in range(d_h*3)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        heads = []\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](x) # Query Matrix\n",
        "            K = self.linears[3*i + 1](x) # Key Matrix\n",
        "            V = self.linears[3*i + 2](x) # Value Matrix\n",
        "\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # MatMul of Q and K -> Scale\n",
        "\n",
        "            head = F.softmax(scaledMatMul) @ V # SoftMax -> MatMul of Q,K and V\n",
        "\n",
        "            heads.append(head) # A Single Head\n",
        "\n",
        "        Z = self.concatLinear(torch.cat((heads), -1)) # Concatenated heads -> Linear Layer\n",
        "\n",
        "        Z = self.dropout(Z)\n",
        "\n",
        "        AddNorm = self.normalize(x + Z) # Output of the First Add&Norm Layer\n",
        "        \n",
        "        Z = self.normalize(self.feed_forward(AddNorm) + AddNorm) # 1st Add&Norm -> Feed Forward -> 2nd Add&Norm\n",
        "\n",
        "        return Z"
      ],
      "metadata": {
        "id": "71IIvzmUYYtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, d_h, dropout, N):\n",
        "        super(EncoderStack, self).__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, src):\n",
        "        for encoder in self.encoders:\n",
        "            src = encoder(src)\n",
        "        return src"
      ],
      "metadata": {
        "id": "Cg67GeB7imYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1): # parameters={}\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_k = self.d_v = int(self.d_model / self.d_h)\n",
        "\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k, bias=False) for _ in range(d_h*3)]) # Linear Layers\n",
        "\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_v, d_model, bias=False) # Linear Layer for the Concatenated Head\n",
        "\n",
        "        self.secondLinear = nn.Linear(d_h * self.d_model, d_model, bias=False) # Linear Layer for the Concatenated Head(second multi-head attention)\n",
        "\n",
        "        self.normalize = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.mask = torch.triu( # Lower Triangular Mask Matrix\n",
        "            torch.tensor([[[-np.inf for _ in range(self.d_k)] for _ in range(self.d_k)] for _ in range(16)]), diagonal=1\n",
        "        )\n",
        "\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        heads1 = []\n",
        "        heads2 = []\n",
        "        for i in range(self.d_h):\n",
        "\n",
        "            # FIRST ATTENTION LAYER OF THE DECODER\n",
        "            ''' Same as decoder, but here we have tgt(target) as the decoder's input. '''\n",
        "            Q = self.linears[3*i](tgt) # Query Matrix\n",
        "            K = self.linears[3*i+1](tgt) # Key Matrix\n",
        "            V = self.linears[3*i+2](tgt) # Value Matrix\n",
        "            \n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix Multiplication of Q and K -> Scale\n",
        "            maskedMat = scaledMatMul + self.mask # Masking, optional\n",
        "            soft = F.softmax(scaledMatMul) # SoftMax\n",
        "\n",
        "            head =  soft @ V # Matrix Multiplication of Scaled and Soft Maxed Q, K Matrices with V\n",
        "\n",
        "            heads1.append(head) # Appending a Single Head\n",
        "\n",
        "        Z1 = self.firstLinear(torch.cat((heads1), dim=-1)) # Concatenated Heads of the First Attention Layer\n",
        "\n",
        "        AddNorm1 = self.normalize(src + Z1) # First Normalizing Layer\n",
        "\n",
        "        for i in range(self.d_h): # Second Attention Layer\n",
        "\n",
        "            # SECOND ATTENTION LAYER OF THE DECODER\n",
        "            ''' A typical Attention layer, however, instead of Q and K matrices, we use the output of the encoder. '''\n",
        "            scaledMat = src @ src.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix Multiplication of SRC and it's Transpose -> Scale\n",
        "\n",
        "            soft = F.softmax(scaledMat) # Soft Max\n",
        "\n",
        "            head = soft @ Z1 # Matrix Multiplication of Scaled and Soft Maxed X, X.T and the Output of the Previous Multi Head Attention Layer\n",
        "\n",
        "            heads2.append(head) # Appending a Single Head\n",
        "\n",
        "        Z2 = self.secondLinear(torch.cat((heads2), dim=-1)) # Concatenated Heads of the Second Attention Layer\n",
        "\n",
        "        AddNorm2 = self.normalize(AddNorm1 + Z2) # Second Normalizing Layer -- The Output of the First Normalizing Layer is Being Used\n",
        "\n",
        "        Z = self.normalize(AddNorm2 + self.feed_forward(AddNorm2)) # Feed Forward -> Normalize\n",
        "\n",
        "        return Z"
      ],
      "metadata": {
        "id": "8Gra_PyaikDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, d_h, dropout, N):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        self.decoders = nn.ModuleList([DecoderLayer(d_model, d_ff, d_h) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        for decoder in self.decoders:\n",
        "            tgt = decoder(src, tgt)\n",
        "        return src"
      ],
      "metadata": {
        "id": "C2VGTD8-ikcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embedding_size=512, d_model=512, d_h = 8, d_ff=2048, vocab_size=32768, dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.linear = nn.Linear(d_model, vocab_size, bias=False) # Final Linear Layer of Our Model\n",
        "        self.dropoutEnc = nn.Dropout(dropout)\n",
        "        self.dropoutDec = nn.Dropout(dropout)\n",
        "        self.softmax = F.softmax\n",
        "        self.embed = Embedding(vocab_size, embedding_size, pad_mask=1)\n",
        "        self.encoderStack = EncoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.decoderStack = DecoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "\n",
        "    def PositionalEncoding(self, seq_len, d_model, n):\n",
        "        P = torch.zeros(seq_len, d_model)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(int(d_model/2)):\n",
        "                denominator = math.pow(n, 2*i/d_model)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        return P\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = (self.embed(src))\n",
        "\n",
        "        tgt = (self.embed(tgt))\n",
        "\n",
        "        pos_encoding = self.PositionalEncoding(self.d_model//self.d_h, self.d_model, 5000)\n",
        "\n",
        "        src = pos_encoding + src\n",
        "\n",
        "        tgt = pos_encoding + tgt\n",
        "\n",
        "        src = self.dropoutEnc(src)\n",
        "\n",
        "        tgt = self.dropoutDec(tgt)\n",
        "\n",
        "        encoderOutput = self.encoderStack(src.float())\n",
        "\n",
        "        decoderOutput = self.decoderStack(encoderOutput, tgt.float())\n",
        "\n",
        "        logits = self.linear(decoderOutput)\n",
        "\n",
        "        probs = self.softmax(logits)\n",
        "\n",
        "        return probs"
      ],
      "metadata": {
        "id": "ULn1jcmkijB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(embedding_size=512, d_model=512, d_h=8, d_ff=2048, vocab_size=32768, dropout=0.1, num_coder_layers=6)"
      ],
      "metadata": {
        "id": "3YozcXkE6mmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "HMbEKbJESGwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    i=0\n",
        "    for source, target in train_dataloader:\n",
        "        \n",
        "        input, labels = source, target\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input, labels)\n",
        "\n",
        "        outputs = torch.argmax(outputs, dim=2)\n",
        "\n",
        "        outputs = outputs.reshape(1, 1024)\n",
        "\n",
        "        labels = labels.reshape(1, 1024)\n",
        "\n",
        "        loss = criterion(torch.tensor(outputs, dtype=torch.float, requires_grad=True), torch.tensor(labels, dtype=float, requires_grad=True))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        i=i+1\n",
        "        if i % 10 == 2:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "4sqWOEjBSG88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}