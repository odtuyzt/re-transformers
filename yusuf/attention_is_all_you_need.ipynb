{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E-kEmBQVsljM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torchtext.datasets as datasets\n",
        "import spacy\n",
        "import warnings\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "casSIlcTsljP"
      },
      "outputs": [],
      "source": [
        "\"\"\"def attention(Q, K, V):\n",
        "    dimension = Q.shape[1]\n",
        "    attention=np.dot(Q, K.T)\n",
        "    is_all =attention/np.sqrt(dimension)\n",
        "    you = softmax(is_all)\n",
        "    need = np.dot(you, V)\n",
        "    return need\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ7C8M15sljQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"def attention(Q,K,V):\n",
        "    m, n = Q.size()\n",
        "    attention = torch.matmul(Q, K.T)\n",
        "    is_all = attention/torch.sqrt(torch.tensor(n))\n",
        "    you = torch.nn.functional.softmax(is_all, dim=-1)\n",
        "    need = torch.matmul(torch.tensor(you), V)\n",
        "    return need\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_udYK9WsljQ"
      },
      "outputs": [],
      "source": [
        "Q = torch.randn(4,3)\n",
        "K = torch.randn(4,3)\n",
        "V = torch.randn(4,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGgSXHGNsljR"
      },
      "outputs": [],
      "source": [
        "\"\"\"def feed_forward(Q,K,V):\n",
        "    m, n = Q.size()\n",
        "    attention = torch.matmul(Q, K.T)\n",
        "    is_all = attention/torch.sqrt(torch.tensor(n))\n",
        "    you = torch.nn.functional.softmax(is_all, dim=0)\n",
        "    need = torch.matmul(torch.tensor(you), V)\n",
        "    linear1 = torch.nn.Linear(n, 2048)(need)\n",
        "    relu = torch.nn.ReLU()(linear1)\n",
        "    linear2 = torch.nn.Linear(2048, 512)(relu)\n",
        "    return linear2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDPG680csljR",
        "outputId": "7f25c0c8-5b4e-4661-f4b7-0a18dce236c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/wy/zrk8x2415z7cybpg4y_2chvm0000gn/T/ipykernel_37720/1859686510.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  need = torch.matmul(torch.tensor(you), V)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0512,  0.1466,  0.0654,  ...,  0.2638,  0.0680,  0.1026],\n",
              "        [-0.0375,  0.0568, -0.0147,  ...,  0.2257, -0.0017,  0.0132],\n",
              "        [ 0.0229,  0.0365,  0.0768,  ...,  0.4782, -0.0735,  0.0136],\n",
              "        [-0.1525,  0.1812, -0.0339,  ...,  0.0854,  0.2075,  0.1902]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#feed_forward(Q,K,V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n48Hd5EBsljS"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"Implements Figure 2\"\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "        \"\"\"        query, key, value = [\n",
        "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for lin, x in zip(self.linears, (query, key, value))\n",
        "        ]\"\"\"\n",
        "        #.view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "        QKVList = [query, key, value]\n",
        "        for i in range(len(lin)):\n",
        "          for lin, x in zip(self.linears, QKVList[i]):\n",
        "            QKVList[i] = [lin(x)]\n",
        "        # 2) Apply attention on all the projected vectors in batch.\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask=None, dropout=self.dropout\n",
        "        )\n",
        "        # 3) \"Concat\" using a view and apply a final linear.\n",
        "        x = (\n",
        "            x.transpose(1, 2)\n",
        "            .contiguous()\n",
        "            .view(nbatches, -1, self.h * self.d_k)\n",
        "        )\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "metadata": {
        "id": "mu4m20xJvbEZ"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "583b6fc52c5b7ee5f2182dab3f72f3a72dfcb1ff68e92bdceeee0ebc62185975"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}